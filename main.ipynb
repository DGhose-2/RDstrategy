{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_utils import *\n",
    "\n",
    "\n",
    "# DATA IMPORT\n",
    "\n",
    "# your working directory for the code files\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "path = cwd + '\\\\Data'\n",
    "\n",
    "\n",
    "TDPorgs_path = path + '\\\\organizations.csv'\n",
    "UKRIorgs_path = path + '\\\\orgs.csv'\n",
    "\n",
    "#Auxiliaries\n",
    "TDPorgs_descr_path = path + '\\\\organization_descriptions.csv'\n",
    "orgProjectLinks_path = path + '\\\\orgProjectsLinks.csv'\n",
    "projects_path = path + '\\\\projects.csv'\n",
    "\n",
    "\n",
    "TDP_orgs = pd.read_csv(TDPorgs_path)\n",
    "UKRI_orgs = pd.read_csv(UKRIorgs_path)\n",
    "#Auxiliaries\n",
    "TDPorgs_descr = pd.read_csv(TDPorgs_descr_path)\n",
    "orgProjectLinks = pd.read_csv(orgProjectLinks_path).drop(columns=['startdate', 'enddate'])\n",
    "projects = pd.read_csv(projects_path)[['projectuuid', 'title', 'potentialimpact', 'leadfunder', 'startdate', 'enddate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the names\n",
    "TDP_orgsnames = name_cleaner(TDP_orgs)\n",
    "UKRI_orgsnames = name_cleaner(UKRI_orgs)\n",
    "\n",
    "TDP_orgs['Cleannames']= TDP_orgsnames #should be in main code\n",
    "UKRI_orgs['Cleannames']= UKRI_orgsnames #should be in main code\n",
    "\n",
    "#removing of same-named companies from TDP\n",
    "TDP_orgs = company_clean(TDP_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of common companies\n",
    "matches = string_matcher(TDP_orgsnames, UKRI_orgsnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text descriptions and project titles together for the reduced, joined data-set\n",
    "orgProjectTexts = info_merger(TDP_orgs, UKRI_orgs,\n",
    "                              match_table = matches,\n",
    "                              df1_desc = TDPorgs_descr,\n",
    "                              df2_info = projects,\n",
    "                              df_links = orgProjectLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utils import *\n",
    "\n",
    "# # orgProjectTexts has been stored an intermediate file to save running the above:\n",
    "# path_int = cwd + '\\\\Intermediate_Files'\n",
    "# orgProjectTexts_path = path_int + '\\\\orgProjectTexts.csv'\n",
    "# orgProjectTexts = pd.read_csv(orgProjectTexts_path)\n",
    "\n",
    "df = presplit_preprocess(orgProjectTexts)\n",
    "\n",
    "# split training-validation and test sets\n",
    "df_trainval, df_test = trainval_test_split(df)\n",
    "\n",
    "# negative examples for training-data:\n",
    "df_trainval = trainval_negs(df_trainval, full_data=df)\n",
    "\n",
    "# all rank combinations to try, for test data:\n",
    "col_order = df_trainval.columns\n",
    "df_test = test_combs(df_test, col_order = col_order)\n",
    "\n",
    "# combine sets again for language processing\n",
    "df_mixed = pd.concat([df_trainval, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute similarity scores\n",
    "df_mixed_sims = similarity_scores(df_mixed, meth='lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general preprocessing before predictive modelling\n",
    "df_mixed_sims = feature_preprocess(df_mixed_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary classification\n",
    "\n",
    "from model_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked ensemble\n",
    "\n",
    "X_train, X_val, y_train, y_val, df_test, n_orgs = final_preprocessing(df_mixed_sims, model=\"ensemble\")\n",
    "run_ensemble(X_train, X_val, y_train, y_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep neural network\n",
    "\n",
    "X_train, X_val, y_train, y_val, df_test, n_orgs = final_preprocessing(df_mixed_sims, model=\"dnn\")\n",
    "run_dnn(X_train, X_val, y_train, y_val, df_test, n_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "X_train, X_val, y_train, y_val, df_test, n_orgs = final_preprocessing(df_mixed_sims, model=\"cnn\")\n",
    "run_cnn(X_train, X_val, y_train, y_val, df_test, n_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "org_features = ['orguuid', 'CB_rank', 'projects_count']\n",
    "proj_features = ['project_length', 'sim', 'proj_month', 'proj_year']\n",
    "\n",
    "X_train, X_val, y_train, y_val, df_test, n_orgs = final_preprocessing(df_mixed_sims, model=\"lstm\")\n",
    "run_lstm(X_train, X_val, y_train, y_val, df_test, org_features = org_features, proj_features = proj_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
